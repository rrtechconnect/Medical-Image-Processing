{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import scipy.io"
      ],
      "metadata": {
        "id": "9EzG2NTPsFEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1de882-7a82-4f41-a828-63132a7cca53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/My Drive/CCE-AIMIA/CHASEDB/'"
      ],
      "metadata": {
        "id": "0zs1FUfMushq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from albumentations import HorizontalFlip, VerticalFlip, ElasticTransform, GridDistortion, OpticalDistortion, CoarseDropout\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "train_dir_path = data_path+\"Training/\"\n",
        "train_images_path = train_dir_path +\"Images/\"\n",
        "test_dir_path = data_path+\"Testing/\"\n",
        "test_images_path =test_dir_path+\"Images/\"\n",
        "train_gt_path = train_dir_path+\"Labels1/\"\n",
        "test_gt_path = test_dir_path +\"Labels1/\"\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\" X = Images and Y = masks \"\"\"\n",
        "    train_x = sorted(glob(train_images_path+\"*.jpg\"))\n",
        "    train_y = sorted(glob(train_gt_path+\"*.png\"))\n",
        "    test_x = sorted(glob(test_images_path+\"*.jpg\"))\n",
        "    test_y = sorted(glob(test_gt_path+\"*.png\"))\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "def augment_data(images, masks, save_path, augment=True):\n",
        "    H = 512\n",
        "    W = 512\n",
        "\n",
        "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
        "        \"\"\" Extracting names \"\"\"\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \"\"\" Reading image and mask \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        #y = imageio.mimread(y)[0]\n",
        "        y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if augment == True:\n",
        "            aug = HorizontalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x1 = augmented[\"image\"]\n",
        "            y1 = augmented[\"mask\"]\n",
        "\n",
        "            aug = VerticalFlip(p=1.0)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x2 = augmented[\"image\"]\n",
        "            y2 = augmented[\"mask\"]\n",
        "\n",
        "            aug = ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x3 = augmented['image']\n",
        "            y3 = augmented['mask']\n",
        "\n",
        "            aug = GridDistortion(p=1)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x4 = augmented['image']\n",
        "            y4 = augmented['mask']\n",
        "\n",
        "            aug = OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)\n",
        "            augmented = aug(image=x, mask=y)\n",
        "            x5 = augmented['image']\n",
        "            y5 = augmented['mask']\n",
        "\n",
        "            X = [x, x1, x2, x3, x4, x5]\n",
        "            Y = [y, y1, y2, y3, y4, y5]\n",
        "\n",
        "        else:\n",
        "            X = [x]\n",
        "            Y = [y]\n",
        "\n",
        "        index = 0\n",
        "        for i, m in zip(X, Y):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(X) == 1:\n",
        "                tmp_image_name = f\"{name}.jpg\"\n",
        "                tmp_mask_name = f\"{name}.jpg\"\n",
        "            else:\n",
        "                tmp_image_name = f\"{name}_{index}.jpg\"\n",
        "                tmp_mask_name = f\"{name}_{index}.jpg\"\n",
        "\n",
        "            image_path = os.path.join(save_path, \"image\", tmp_image_name)\n",
        "            mask_path = os.path.join(save_path, \"mask\", tmp_mask_name)\n",
        "\n",
        "            cv2.imwrite(image_path, i)\n",
        "            cv2.imwrite(mask_path, m)\n",
        "\n",
        "            index += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    \"\"\" Load the data \"\"\"\n",
        "    data_path = \"/content/drive/My Drive/CCE-AIMIA/CHASEDB/\"\n",
        "    (train_x, train_y), (test_x, test_y) = load_data(data_path)\n",
        "\n",
        "    print(f\"No. of Training images: {len(train_x)}\")\n",
        "    print(f\"No. of Training masks: {len(train_y)}\")\n",
        "    print(f\"No.Testing images: {len(test_x)}\")\n",
        "    print(f\"No.Testing masks:  {len(test_y)}\")\n",
        "    \"\"\" Creating directories \"\"\"\n",
        "    create_dir(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data/train/image\")\n",
        "    create_dir(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data/train/mask\")\n",
        "    create_dir(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data/test/image\")\n",
        "    create_dir(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data/test/mask\")\n",
        "\n",
        "    augment_data(train_x, train_y, \"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data/train/\", augment=True)\n",
        "    augment_data(test_x, test_y, \"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data/test/\", augment=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E0jmLR9-6tr",
        "outputId": "570ef5cc-a9fa-4f6a-a36f-319c41dd2945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of Training images: 20\n",
            "No. of Training masks: 20\n",
            "No.Testing images: 8\n",
            "No.Testing masks:  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:40<00:00,  2.04s/it]\n",
            "100%|██████████| 8/8 [00:11<00:00,  1.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (512, 512, 3)\n",
        "    model = build_unet(input_shape)\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNyhrjYCCNPV",
        "outputId": "912c054c-ed75-487a-9d10-5c0cb5de2d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512, 512, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 512, 512, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512, 512, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 512, 512, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 256, 256, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['activation_3[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_4[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['activation_4[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_5[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_11[0][0]']          \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                2)                                'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128, 128, 25  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_12[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 128, 25  590080      ['activation_12[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 128, 25  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_13[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 256, 256, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 256, 256, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 256, 256, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 512, 512, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 512, 512, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 512, 512, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 512, 512, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,055,297\n",
            "Trainable params: 31,043,521\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "EUz8ZNXID9Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch_size=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory to save files \"\"\"\n",
        "    create_dir(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/files\")\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    batch_size = 2\n",
        "    lr = 1e-4\n",
        "    num_epochs = 100\n",
        "    model_path = os.path.join(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/files\", \"model_chasedb.h5\")\n",
        "    csv_path = os.path.join(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/files\", \"data_chasedb.csv\")\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    dataset_path = \"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data\"\n",
        "    train_path = os.path.join(dataset_path, \"train\")\n",
        "    valid_path = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "    train_x, train_y = load_data(train_path)\n",
        "    train_x, train_y = shuffling(train_x, train_y)\n",
        "    valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "    train_steps = len(train_x)//batch_size\n",
        "    valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_setps += 1\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = build_unet((H, W, 3))\n",
        "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[['accuracy'],dice_coef, iou, Recall(), Precision()])\n",
        "    # model.summary()\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, min_lr=1e-6, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=False)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_setps,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAUPmIAHCTlX",
        "outputId": "7cb84f8a-d6ca-4885-e050-9b20ea006ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 120 - 120\n",
            "Valid: 8 - 8\n",
            "Epoch 1/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.7076 - dice_coef: 0.3348 - iou: 0.2050 - recall_1: 0.6300 - precision_1: 0.3924\n",
            "Epoch 1: val_loss improved from inf to 0.89089, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 35s 552ms/step - loss: 0.6652 - accuracy: 0.7076 - dice_coef: 0.3348 - iou: 0.2050 - recall_1: 0.6300 - precision_1: 0.3924 - val_loss: 0.8909 - val_accuracy: 0.8572 - val_dice_coef: 0.1091 - val_iou: 0.0577 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8437 - dice_coef: 0.5133 - iou: 0.3460 - recall_1: 0.4828 - precision_1: 0.7694\n",
            "Epoch 2: val_loss did not improve from 0.89089\n",
            "60/60 [==============================] - 32s 534ms/step - loss: 0.4867 - accuracy: 0.8437 - dice_coef: 0.5133 - iou: 0.3460 - recall_1: 0.4828 - precision_1: 0.7694 - val_loss: 0.9056 - val_accuracy: 0.8579 - val_dice_coef: 0.0944 - val_iou: 0.0496 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.8525 - dice_coef: 0.5742 - iou: 0.4034 - recall_1: 0.4704 - precision_1: 0.8311\n",
            "Epoch 3: val_loss did not improve from 0.89089\n",
            "60/60 [==============================] - 31s 517ms/step - loss: 0.4258 - accuracy: 0.8525 - dice_coef: 0.5742 - iou: 0.4034 - recall_1: 0.4704 - precision_1: 0.8311 - val_loss: 0.9256 - val_accuracy: 0.8579 - val_dice_coef: 0.0744 - val_iou: 0.0387 - val_recall_1: 0.0000e+00 - val_precision_1: 0.0000e+00 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8567 - dice_coef: 0.6165 - iou: 0.4462 - recall_1: 0.4642 - precision_1: 0.8638\n",
            "Epoch 4: val_loss did not improve from 0.89089\n",
            "60/60 [==============================] - 32s 531ms/step - loss: 0.3835 - accuracy: 0.8567 - dice_coef: 0.6165 - iou: 0.4462 - recall_1: 0.4642 - precision_1: 0.8638 - val_loss: 0.9441 - val_accuracy: 0.8565 - val_dice_coef: 0.0559 - val_iou: 0.0287 - val_recall_1: 5.1015e-04 - val_precision_1: 0.0500 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8593 - dice_coef: 0.6499 - iou: 0.4819 - recall_1: 0.4596 - precision_1: 0.8852\n",
            "Epoch 5: val_loss did not improve from 0.89089\n",
            "60/60 [==============================] - 32s 527ms/step - loss: 0.3501 - accuracy: 0.8593 - dice_coef: 0.6499 - iou: 0.4819 - recall_1: 0.4596 - precision_1: 0.8852 - val_loss: 0.9444 - val_accuracy: 0.8523 - val_dice_coef: 0.0556 - val_iou: 0.0286 - val_recall_1: 0.0048 - val_precision_1: 0.1052 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3220 - accuracy: 0.8612 - dice_coef: 0.6780 - iou: 0.5134 - recall_1: 0.4553 - precision_1: 0.9018\n",
            "Epoch 6: val_loss improved from 0.89089 to 0.86386, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 35s 592ms/step - loss: 0.3220 - accuracy: 0.8612 - dice_coef: 0.6780 - iou: 0.5134 - recall_1: 0.4553 - precision_1: 0.9018 - val_loss: 0.8639 - val_accuracy: 0.8491 - val_dice_coef: 0.1361 - val_iou: 0.0734 - val_recall_1: 0.0452 - val_precision_1: 0.3461 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8624 - dice_coef: 0.7007 - iou: 0.5399 - recall_1: 0.4520 - precision_1: 0.9127\n",
            "Epoch 7: val_loss improved from 0.86386 to 0.71019, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 596ms/step - loss: 0.2993 - accuracy: 0.8624 - dice_coef: 0.7007 - iou: 0.5399 - recall_1: 0.4520 - precision_1: 0.9127 - val_loss: 0.7102 - val_accuracy: 0.8430 - val_dice_coef: 0.2898 - val_iou: 0.1709 - val_recall_1: 0.1507 - val_precision_1: 0.4533 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.8627 - dice_coef: 0.7153 - iou: 0.5573 - recall_1: 0.4496 - precision_1: 0.9158\n",
            "Epoch 8: val_loss improved from 0.71019 to 0.61612, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 593ms/step - loss: 0.2847 - accuracy: 0.8627 - dice_coef: 0.7153 - iou: 0.5573 - recall_1: 0.4496 - precision_1: 0.9158 - val_loss: 0.6161 - val_accuracy: 0.8433 - val_dice_coef: 0.3839 - val_iou: 0.2388 - val_recall_1: 0.2284 - val_precision_1: 0.5140 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.8635 - dice_coef: 0.7318 - iou: 0.5776 - recall_1: 0.4475 - precision_1: 0.9229\n",
            "Epoch 9: val_loss improved from 0.61612 to 0.49005, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 600ms/step - loss: 0.2682 - accuracy: 0.8635 - dice_coef: 0.7318 - iou: 0.5776 - recall_1: 0.4475 - precision_1: 0.9229 - val_loss: 0.4900 - val_accuracy: 0.8636 - val_dice_coef: 0.5100 - val_iou: 0.3444 - val_recall_1: 0.2896 - val_precision_1: 0.7497 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.8644 - dice_coef: 0.7484 - iou: 0.5986 - recall_1: 0.4459 - precision_1: 0.9310\n",
            "Epoch 10: val_loss improved from 0.49005 to 0.39281, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 597ms/step - loss: 0.2516 - accuracy: 0.8644 - dice_coef: 0.7484 - iou: 0.5986 - recall_1: 0.4459 - precision_1: 0.9310 - val_loss: 0.3928 - val_accuracy: 0.8753 - val_dice_coef: 0.6072 - val_iou: 0.4381 - val_recall_1: 0.3384 - val_precision_1: 0.9066 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.8649 - dice_coef: 0.7610 - iou: 0.6148 - recall_1: 0.4443 - precision_1: 0.9358\n",
            "Epoch 11: val_loss improved from 0.39281 to 0.34992, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 602ms/step - loss: 0.2390 - accuracy: 0.8649 - dice_coef: 0.7610 - iou: 0.6148 - recall_1: 0.4443 - precision_1: 0.9358 - val_loss: 0.3499 - val_accuracy: 0.8755 - val_dice_coef: 0.6501 - val_iou: 0.4824 - val_recall_1: 0.3752 - val_precision_1: 0.8915 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.8655 - dice_coef: 0.7741 - iou: 0.6319 - recall_1: 0.4427 - precision_1: 0.9417\n",
            "Epoch 12: val_loss improved from 0.34992 to 0.32336, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 37s 607ms/step - loss: 0.2259 - accuracy: 0.8655 - dice_coef: 0.7741 - iou: 0.6319 - recall_1: 0.4427 - precision_1: 0.9417 - val_loss: 0.3234 - val_accuracy: 0.8772 - val_dice_coef: 0.6766 - val_iou: 0.5120 - val_recall_1: 0.3760 - val_precision_1: 0.9103 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.8661 - dice_coef: 0.7862 - iou: 0.6482 - recall_1: 0.4420 - precision_1: 0.9471\n",
            "Epoch 13: val_loss improved from 0.32336 to 0.31278, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 603ms/step - loss: 0.2138 - accuracy: 0.8661 - dice_coef: 0.7862 - iou: 0.6482 - recall_1: 0.4420 - precision_1: 0.9471 - val_loss: 0.3128 - val_accuracy: 0.8770 - val_dice_coef: 0.6872 - val_iou: 0.5247 - val_recall_1: 0.3894 - val_precision_1: 0.9031 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.8665 - dice_coef: 0.7958 - iou: 0.6614 - recall_1: 0.4417 - precision_1: 0.9508\n",
            "Epoch 14: val_loss improved from 0.31278 to 0.30373, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 603ms/step - loss: 0.2042 - accuracy: 0.8665 - dice_coef: 0.7958 - iou: 0.6614 - recall_1: 0.4417 - precision_1: 0.9508 - val_loss: 0.3037 - val_accuracy: 0.8768 - val_dice_coef: 0.6963 - val_iou: 0.5348 - val_recall_1: 0.3922 - val_precision_1: 0.9002 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.8664 - dice_coef: 0.8001 - iou: 0.6673 - recall_1: 0.4406 - precision_1: 0.9506\n",
            "Epoch 15: val_loss did not improve from 0.30373\n",
            "60/60 [==============================] - 31s 520ms/step - loss: 0.1999 - accuracy: 0.8664 - dice_coef: 0.8001 - iou: 0.6673 - recall_1: 0.4406 - precision_1: 0.9506 - val_loss: 0.3190 - val_accuracy: 0.8770 - val_dice_coef: 0.6810 - val_iou: 0.5177 - val_recall_1: 0.3495 - val_precision_1: 0.9214 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.8665 - dice_coef: 0.8051 - iou: 0.6743 - recall_1: 0.4401 - precision_1: 0.9516\n",
            "Epoch 16: val_loss did not improve from 0.30373\n",
            "60/60 [==============================] - 31s 520ms/step - loss: 0.1949 - accuracy: 0.8665 - dice_coef: 0.8051 - iou: 0.6743 - recall_1: 0.4401 - precision_1: 0.9516 - val_loss: 0.3253 - val_accuracy: 0.8762 - val_dice_coef: 0.6747 - val_iou: 0.5113 - val_recall_1: 0.3434 - val_precision_1: 0.9151 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.8671 - dice_coef: 0.8150 - iou: 0.6882 - recall_1: 0.4400 - precision_1: 0.9569\n",
            "Epoch 17: val_loss did not improve from 0.30373\n",
            "60/60 [==============================] - 31s 520ms/step - loss: 0.1850 - accuracy: 0.8671 - dice_coef: 0.8150 - iou: 0.6882 - recall_1: 0.4400 - precision_1: 0.9569 - val_loss: 0.3148 - val_accuracy: 0.8760 - val_dice_coef: 0.6852 - val_iou: 0.5227 - val_recall_1: 0.3672 - val_precision_1: 0.9017 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.8674 - dice_coef: 0.8224 - iou: 0.6988 - recall_1: 0.4396 - precision_1: 0.9603\n",
            "Epoch 18: val_loss did not improve from 0.30373\n",
            "60/60 [==============================] - 32s 530ms/step - loss: 0.1776 - accuracy: 0.8674 - dice_coef: 0.8224 - iou: 0.6988 - recall_1: 0.4396 - precision_1: 0.9603 - val_loss: 0.3069 - val_accuracy: 0.8769 - val_dice_coef: 0.6931 - val_iou: 0.5317 - val_recall_1: 0.3531 - val_precision_1: 0.9185 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.8677 - dice_coef: 0.8283 - iou: 0.7073 - recall_1: 0.4391 - precision_1: 0.9630\n",
            "Epoch 19: val_loss improved from 0.30373 to 0.30226, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 35s 588ms/step - loss: 0.1717 - accuracy: 0.8677 - dice_coef: 0.8283 - iou: 0.7073 - recall_1: 0.4391 - precision_1: 0.9630 - val_loss: 0.3023 - val_accuracy: 0.8766 - val_dice_coef: 0.6977 - val_iou: 0.5378 - val_recall_1: 0.3600 - val_precision_1: 0.9123 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.8677 - dice_coef: 0.8301 - iou: 0.7099 - recall_1: 0.4384 - precision_1: 0.9625\n",
            "Epoch 20: val_loss improved from 0.30226 to 0.28541, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 37s 608ms/step - loss: 0.1699 - accuracy: 0.8677 - dice_coef: 0.8301 - iou: 0.7099 - recall_1: 0.4384 - precision_1: 0.9625 - val_loss: 0.2854 - val_accuracy: 0.8767 - val_dice_coef: 0.7146 - val_iou: 0.5572 - val_recall_1: 0.3887 - val_precision_1: 0.8996 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.8676 - dice_coef: 0.8325 - iou: 0.7136 - recall_1: 0.4388 - precision_1: 0.9619\n",
            "Epoch 21: val_loss did not improve from 0.28541\n",
            "60/60 [==============================] - 32s 532ms/step - loss: 0.1675 - accuracy: 0.8676 - dice_coef: 0.8325 - iou: 0.7136 - recall_1: 0.4388 - precision_1: 0.9619 - val_loss: 0.2885 - val_accuracy: 0.8772 - val_dice_coef: 0.7115 - val_iou: 0.5538 - val_recall_1: 0.3647 - val_precision_1: 0.9146 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.8679 - dice_coef: 0.8377 - iou: 0.7211 - recall_1: 0.4389 - precision_1: 0.9641\n",
            "Epoch 22: val_loss did not improve from 0.28541\n",
            "60/60 [==============================] - 31s 523ms/step - loss: 0.1623 - accuracy: 0.8679 - dice_coef: 0.8377 - iou: 0.7211 - recall_1: 0.4389 - precision_1: 0.9641 - val_loss: 0.3006 - val_accuracy: 0.8767 - val_dice_coef: 0.6994 - val_iou: 0.5393 - val_recall_1: 0.3419 - val_precision_1: 0.9208 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.8683 - dice_coef: 0.8450 - iou: 0.7319 - recall_1: 0.4378 - precision_1: 0.9689\n",
            "Epoch 23: val_loss did not improve from 0.28541\n",
            "60/60 [==============================] - 31s 521ms/step - loss: 0.1550 - accuracy: 0.8683 - dice_coef: 0.8450 - iou: 0.7319 - recall_1: 0.4378 - precision_1: 0.9689 - val_loss: 0.2881 - val_accuracy: 0.8764 - val_dice_coef: 0.7119 - val_iou: 0.5542 - val_recall_1: 0.3685 - val_precision_1: 0.9041 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.8686 - dice_coef: 0.8496 - iou: 0.7388 - recall_1: 0.4385 - precision_1: 0.9705\n",
            "Epoch 24: val_loss improved from 0.28541 to 0.28046, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 607ms/step - loss: 0.1504 - accuracy: 0.8686 - dice_coef: 0.8496 - iou: 0.7388 - recall_1: 0.4385 - precision_1: 0.9705 - val_loss: 0.2805 - val_accuracy: 0.8764 - val_dice_coef: 0.7195 - val_iou: 0.5630 - val_recall_1: 0.3864 - val_precision_1: 0.8956 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1491 - accuracy: 0.8686 - dice_coef: 0.8509 - iou: 0.7409 - recall_1: 0.4379 - precision_1: 0.9708\n",
            "Epoch 25: val_loss did not improve from 0.28046\n",
            "60/60 [==============================] - 32s 534ms/step - loss: 0.1491 - accuracy: 0.8686 - dice_coef: 0.8509 - iou: 0.7409 - recall_1: 0.4379 - precision_1: 0.9708 - val_loss: 0.3205 - val_accuracy: 0.8760 - val_dice_coef: 0.6795 - val_iou: 0.5162 - val_recall_1: 0.3127 - val_precision_1: 0.9290 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.8683 - dice_coef: 0.8487 - iou: 0.7375 - recall_1: 0.4374 - precision_1: 0.9684\n",
            "Epoch 26: val_loss did not improve from 0.28046\n",
            "60/60 [==============================] - 31s 520ms/step - loss: 0.1513 - accuracy: 0.8683 - dice_coef: 0.8487 - iou: 0.7375 - recall_1: 0.4374 - precision_1: 0.9684 - val_loss: 0.2987 - val_accuracy: 0.8766 - val_dice_coef: 0.7013 - val_iou: 0.5410 - val_recall_1: 0.3342 - val_precision_1: 0.9248 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.8684 - dice_coef: 0.8516 - iou: 0.7419 - recall_1: 0.4375 - precision_1: 0.9692\n",
            "Epoch 27: val_loss improved from 0.28046 to 0.27184, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 599ms/step - loss: 0.1484 - accuracy: 0.8684 - dice_coef: 0.8516 - iou: 0.7419 - recall_1: 0.4375 - precision_1: 0.9692 - val_loss: 0.2718 - val_accuracy: 0.8763 - val_dice_coef: 0.7282 - val_iou: 0.5735 - val_recall_1: 0.3996 - val_precision_1: 0.8907 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.8687 - dice_coef: 0.8563 - iou: 0.7490 - recall_1: 0.4373 - precision_1: 0.9719\n",
            "Epoch 28: val_loss did not improve from 0.27184\n",
            "60/60 [==============================] - 31s 524ms/step - loss: 0.1437 - accuracy: 0.8687 - dice_coef: 0.8563 - iou: 0.7490 - recall_1: 0.4373 - precision_1: 0.9719 - val_loss: 0.2875 - val_accuracy: 0.8761 - val_dice_coef: 0.7125 - val_iou: 0.5548 - val_recall_1: 0.3631 - val_precision_1: 0.9030 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.8688 - dice_coef: 0.8596 - iou: 0.7540 - recall_1: 0.4381 - precision_1: 0.9729\n",
            "Epoch 29: val_loss did not improve from 0.27184\n",
            "60/60 [==============================] - 31s 522ms/step - loss: 0.1404 - accuracy: 0.8688 - dice_coef: 0.8596 - iou: 0.7540 - recall_1: 0.4381 - precision_1: 0.9729 - val_loss: 0.2934 - val_accuracy: 0.8758 - val_dice_coef: 0.7066 - val_iou: 0.5478 - val_recall_1: 0.3573 - val_precision_1: 0.9024 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.8689 - dice_coef: 0.8621 - iou: 0.7579 - recall_1: 0.4381 - precision_1: 0.9739\n",
            "Epoch 30: val_loss did not improve from 0.27184\n",
            "60/60 [==============================] - 31s 519ms/step - loss: 0.1379 - accuracy: 0.8689 - dice_coef: 0.8621 - iou: 0.7579 - recall_1: 0.4381 - precision_1: 0.9739 - val_loss: 0.2732 - val_accuracy: 0.8766 - val_dice_coef: 0.7268 - val_iou: 0.5724 - val_recall_1: 0.3811 - val_precision_1: 0.9019 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.8690 - dice_coef: 0.8641 - iou: 0.7610 - recall_1: 0.4377 - precision_1: 0.9752\n",
            "Epoch 31: val_loss improved from 0.27184 to 0.26801, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 35s 593ms/step - loss: 0.1359 - accuracy: 0.8690 - dice_coef: 0.8641 - iou: 0.7610 - recall_1: 0.4377 - precision_1: 0.9752 - val_loss: 0.2680 - val_accuracy: 0.8772 - val_dice_coef: 0.7320 - val_iou: 0.5789 - val_recall_1: 0.3745 - val_precision_1: 0.9106 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.8694 - dice_coef: 0.8700 - iou: 0.7701 - recall_1: 0.4387 - precision_1: 0.9779\n",
            "Epoch 32: val_loss did not improve from 0.26801\n",
            "60/60 [==============================] - 31s 523ms/step - loss: 0.1300 - accuracy: 0.8694 - dice_coef: 0.8700 - iou: 0.7701 - recall_1: 0.4387 - precision_1: 0.9779 - val_loss: 0.2743 - val_accuracy: 0.8767 - val_dice_coef: 0.7257 - val_iou: 0.5708 - val_recall_1: 0.3740 - val_precision_1: 0.9058 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.8696 - dice_coef: 0.8739 - iou: 0.7762 - recall_1: 0.4380 - precision_1: 0.9804\n",
            "Epoch 33: val_loss did not improve from 0.26801\n",
            "60/60 [==============================] - 32s 532ms/step - loss: 0.1261 - accuracy: 0.8696 - dice_coef: 0.8739 - iou: 0.7762 - recall_1: 0.4380 - precision_1: 0.9804 - val_loss: 0.2698 - val_accuracy: 0.8768 - val_dice_coef: 0.7302 - val_iou: 0.5766 - val_recall_1: 0.3764 - val_precision_1: 0.9069 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.8698 - dice_coef: 0.8766 - iou: 0.7806 - recall_1: 0.4387 - precision_1: 0.9813\n",
            "Epoch 34: val_loss did not improve from 0.26801\n",
            "60/60 [==============================] - 32s 530ms/step - loss: 0.1234 - accuracy: 0.8698 - dice_coef: 0.8766 - iou: 0.7806 - recall_1: 0.4387 - precision_1: 0.9813 - val_loss: 0.2734 - val_accuracy: 0.8765 - val_dice_coef: 0.7266 - val_iou: 0.5722 - val_recall_1: 0.3760 - val_precision_1: 0.9031 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.8699 - dice_coef: 0.8794 - iou: 0.7850 - recall_1: 0.4385 - precision_1: 0.9824\n",
            "Epoch 35: val_loss improved from 0.26801 to 0.26703, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 607ms/step - loss: 0.1206 - accuracy: 0.8699 - dice_coef: 0.8794 - iou: 0.7850 - recall_1: 0.4385 - precision_1: 0.9824 - val_loss: 0.2670 - val_accuracy: 0.8764 - val_dice_coef: 0.7330 - val_iou: 0.5801 - val_recall_1: 0.3901 - val_precision_1: 0.8967 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.8699 - dice_coef: 0.8804 - iou: 0.7866 - recall_1: 0.4382 - precision_1: 0.9827\n",
            "Epoch 36: val_loss improved from 0.26703 to 0.25761, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 599ms/step - loss: 0.1196 - accuracy: 0.8699 - dice_coef: 0.8804 - iou: 0.7866 - recall_1: 0.4382 - precision_1: 0.9827 - val_loss: 0.2576 - val_accuracy: 0.8769 - val_dice_coef: 0.7424 - val_iou: 0.5915 - val_recall_1: 0.3994 - val_precision_1: 0.8967 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.8700 - dice_coef: 0.8818 - iou: 0.7889 - recall_1: 0.4385 - precision_1: 0.9832\n",
            "Epoch 37: val_loss did not improve from 0.25761\n",
            "60/60 [==============================] - 32s 529ms/step - loss: 0.1182 - accuracy: 0.8700 - dice_coef: 0.8818 - iou: 0.7889 - recall_1: 0.4385 - precision_1: 0.9832 - val_loss: 0.2605 - val_accuracy: 0.8770 - val_dice_coef: 0.7395 - val_iou: 0.5880 - val_recall_1: 0.3878 - val_precision_1: 0.9024 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.8701 - dice_coef: 0.8843 - iou: 0.7928 - recall_1: 0.4386 - precision_1: 0.9843\n",
            "Epoch 38: val_loss did not improve from 0.25761\n",
            "60/60 [==============================] - 31s 521ms/step - loss: 0.1157 - accuracy: 0.8701 - dice_coef: 0.8843 - iou: 0.7928 - recall_1: 0.4386 - precision_1: 0.9843 - val_loss: 0.2811 - val_accuracy: 0.8768 - val_dice_coef: 0.7189 - val_iou: 0.5633 - val_recall_1: 0.3495 - val_precision_1: 0.9183 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.8701 - dice_coef: 0.8855 - iou: 0.7948 - recall_1: 0.4390 - precision_1: 0.9845\n",
            "Epoch 39: val_loss did not improve from 0.25761\n",
            "60/60 [==============================] - 32s 530ms/step - loss: 0.1145 - accuracy: 0.8701 - dice_coef: 0.8855 - iou: 0.7948 - recall_1: 0.4390 - precision_1: 0.9845 - val_loss: 0.2748 - val_accuracy: 0.8769 - val_dice_coef: 0.7252 - val_iou: 0.5715 - val_recall_1: 0.3595 - val_precision_1: 0.9155 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.8701 - dice_coef: 0.8853 - iou: 0.7944 - recall_1: 0.4386 - precision_1: 0.9841\n",
            "Epoch 40: val_loss did not improve from 0.25761\n",
            "60/60 [==============================] - 32s 531ms/step - loss: 0.1147 - accuracy: 0.8701 - dice_coef: 0.8853 - iou: 0.7944 - recall_1: 0.4386 - precision_1: 0.9841 - val_loss: 0.2679 - val_accuracy: 0.8769 - val_dice_coef: 0.7321 - val_iou: 0.5795 - val_recall_1: 0.3723 - val_precision_1: 0.9092 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.8701 - dice_coef: 0.8861 - iou: 0.7958 - recall_1: 0.4388 - precision_1: 0.9840\n",
            "Epoch 41: val_loss did not improve from 0.25761\n",
            "\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "60/60 [==============================] - 32s 533ms/step - loss: 0.1139 - accuracy: 0.8701 - dice_coef: 0.8861 - iou: 0.7958 - recall_1: 0.4388 - precision_1: 0.9840 - val_loss: 0.2695 - val_accuracy: 0.8766 - val_dice_coef: 0.7305 - val_iou: 0.5774 - val_recall_1: 0.3724 - val_precision_1: 0.9059 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.8705 - dice_coef: 0.8919 - iou: 0.8052 - recall_1: 0.4386 - precision_1: 0.9877\n",
            "Epoch 42: val_loss improved from 0.25761 to 0.25496, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 596ms/step - loss: 0.1081 - accuracy: 0.8705 - dice_coef: 0.8919 - iou: 0.8052 - recall_1: 0.4386 - precision_1: 0.9877 - val_loss: 0.2550 - val_accuracy: 0.8777 - val_dice_coef: 0.7450 - val_iou: 0.5952 - val_recall_1: 0.3762 - val_precision_1: 0.9155 - lr: 1.0000e-05\n",
            "Epoch 43/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.8709 - dice_coef: 0.8994 - iou: 0.8174 - recall_1: 0.4397 - precision_1: 0.9912\n",
            "Epoch 43: val_loss did not improve from 0.25496\n",
            "60/60 [==============================] - 32s 532ms/step - loss: 0.1006 - accuracy: 0.8709 - dice_coef: 0.8994 - iou: 0.8174 - recall_1: 0.4397 - precision_1: 0.9912 - val_loss: 0.2552 - val_accuracy: 0.8777 - val_dice_coef: 0.7448 - val_iou: 0.5949 - val_recall_1: 0.3739 - val_precision_1: 0.9170 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.8711 - dice_coef: 0.9024 - iou: 0.8223 - recall_1: 0.4398 - precision_1: 0.9926\n",
            "Epoch 44: val_loss did not improve from 0.25496\n",
            "60/60 [==============================] - 31s 521ms/step - loss: 0.0976 - accuracy: 0.8711 - dice_coef: 0.9024 - iou: 0.8223 - recall_1: 0.4398 - precision_1: 0.9926 - val_loss: 0.2551 - val_accuracy: 0.8778 - val_dice_coef: 0.7449 - val_iou: 0.5950 - val_recall_1: 0.3734 - val_precision_1: 0.9177 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.8712 - dice_coef: 0.9044 - iou: 0.8257 - recall_1: 0.4398 - precision_1: 0.9934\n",
            "Epoch 45: val_loss did not improve from 0.25496\n",
            "60/60 [==============================] - 31s 520ms/step - loss: 0.0956 - accuracy: 0.8712 - dice_coef: 0.9044 - iou: 0.8257 - recall_1: 0.4398 - precision_1: 0.9934 - val_loss: 0.2550 - val_accuracy: 0.8778 - val_dice_coef: 0.7450 - val_iou: 0.5952 - val_recall_1: 0.3734 - val_precision_1: 0.9177 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.8713 - dice_coef: 0.9060 - iou: 0.8283 - recall_1: 0.4397 - precision_1: 0.9941\n",
            "Epoch 46: val_loss improved from 0.25496 to 0.25487, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 35s 591ms/step - loss: 0.0940 - accuracy: 0.8713 - dice_coef: 0.9060 - iou: 0.8283 - recall_1: 0.4397 - precision_1: 0.9941 - val_loss: 0.2549 - val_accuracy: 0.8778 - val_dice_coef: 0.7451 - val_iou: 0.5953 - val_recall_1: 0.3737 - val_precision_1: 0.9176 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.8713 - dice_coef: 0.9072 - iou: 0.8304 - recall_1: 0.4397 - precision_1: 0.9946\n",
            "Epoch 47: val_loss improved from 0.25487 to 0.25481, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 596ms/step - loss: 0.0928 - accuracy: 0.8713 - dice_coef: 0.9072 - iou: 0.8304 - recall_1: 0.4397 - precision_1: 0.9946 - val_loss: 0.2548 - val_accuracy: 0.8778 - val_dice_coef: 0.7452 - val_iou: 0.5954 - val_recall_1: 0.3737 - val_precision_1: 0.9173 - lr: 1.0000e-05\n",
            "Epoch 48/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0917 - accuracy: 0.8714 - dice_coef: 0.9083 - iou: 0.8322 - recall_1: 0.4397 - precision_1: 0.9949\n",
            "Epoch 48: val_loss did not improve from 0.25481\n",
            "60/60 [==============================] - 32s 533ms/step - loss: 0.0917 - accuracy: 0.8714 - dice_coef: 0.9083 - iou: 0.8322 - recall_1: 0.4397 - precision_1: 0.9949 - val_loss: 0.2548 - val_accuracy: 0.8777 - val_dice_coef: 0.7452 - val_iou: 0.5954 - val_recall_1: 0.3736 - val_precision_1: 0.9173 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.8714 - dice_coef: 0.9093 - iou: 0.8338 - recall_1: 0.4397 - precision_1: 0.9953\n",
            "Epoch 49: val_loss improved from 0.25481 to 0.25480, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 595ms/step - loss: 0.0907 - accuracy: 0.8714 - dice_coef: 0.9093 - iou: 0.8338 - recall_1: 0.4397 - precision_1: 0.9953 - val_loss: 0.2548 - val_accuracy: 0.8777 - val_dice_coef: 0.7452 - val_iou: 0.5954 - val_recall_1: 0.3739 - val_precision_1: 0.9171 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.8714 - dice_coef: 0.9101 - iou: 0.8352 - recall_1: 0.4397 - precision_1: 0.9955\n",
            "Epoch 50: val_loss improved from 0.25480 to 0.25480, saving model to /content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\n",
            "60/60 [==============================] - 36s 600ms/step - loss: 0.0899 - accuracy: 0.8714 - dice_coef: 0.9101 - iou: 0.8352 - recall_1: 0.4397 - precision_1: 0.9955 - val_loss: 0.2548 - val_accuracy: 0.8777 - val_dice_coef: 0.7452 - val_iou: 0.5954 - val_recall_1: 0.3739 - val_precision_1: 0.9170 - lr: 1.0000e-05\n",
            "Epoch 51/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.8715 - dice_coef: 0.9108 - iou: 0.8364 - recall_1: 0.4396 - precision_1: 0.9958\n",
            "Epoch 51: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 532ms/step - loss: 0.0892 - accuracy: 0.8715 - dice_coef: 0.9108 - iou: 0.8364 - recall_1: 0.4396 - precision_1: 0.9958 - val_loss: 0.2549 - val_accuracy: 0.8777 - val_dice_coef: 0.7451 - val_iou: 0.5953 - val_recall_1: 0.3739 - val_precision_1: 0.9171 - lr: 1.0000e-05\n",
            "Epoch 52/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.8715 - dice_coef: 0.9115 - iou: 0.8376 - recall_1: 0.4396 - precision_1: 0.9959\n",
            "Epoch 52: val_loss did not improve from 0.25480\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "60/60 [==============================] - 31s 521ms/step - loss: 0.0885 - accuracy: 0.8715 - dice_coef: 0.9115 - iou: 0.8376 - recall_1: 0.4396 - precision_1: 0.9959 - val_loss: 0.2550 - val_accuracy: 0.8777 - val_dice_coef: 0.7450 - val_iou: 0.5952 - val_recall_1: 0.3738 - val_precision_1: 0.9170 - lr: 1.0000e-05\n",
            "Epoch 53/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.8715 - dice_coef: 0.9121 - iou: 0.8385 - recall_1: 0.4397 - precision_1: 0.9961\n",
            "Epoch 53: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 531ms/step - loss: 0.0879 - accuracy: 0.8715 - dice_coef: 0.9121 - iou: 0.8385 - recall_1: 0.4397 - precision_1: 0.9961 - val_loss: 0.2551 - val_accuracy: 0.8777 - val_dice_coef: 0.7449 - val_iou: 0.5950 - val_recall_1: 0.3738 - val_precision_1: 0.9169 - lr: 1.0000e-06\n",
            "Epoch 54/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.8715 - dice_coef: 0.9122 - iou: 0.8387 - recall_1: 0.4396 - precision_1: 0.9961\n",
            "Epoch 54: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 526ms/step - loss: 0.0878 - accuracy: 0.8715 - dice_coef: 0.9122 - iou: 0.8387 - recall_1: 0.4396 - precision_1: 0.9961 - val_loss: 0.2550 - val_accuracy: 0.8777 - val_dice_coef: 0.7450 - val_iou: 0.5951 - val_recall_1: 0.3740 - val_precision_1: 0.9167 - lr: 1.0000e-06\n",
            "Epoch 55/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.8715 - dice_coef: 0.9123 - iou: 0.8388 - recall_1: 0.4396 - precision_1: 0.9962\n",
            "Epoch 55: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 528ms/step - loss: 0.0877 - accuracy: 0.8715 - dice_coef: 0.9123 - iou: 0.8388 - recall_1: 0.4396 - precision_1: 0.9962 - val_loss: 0.2550 - val_accuracy: 0.8777 - val_dice_coef: 0.7450 - val_iou: 0.5952 - val_recall_1: 0.3741 - val_precision_1: 0.9166 - lr: 1.0000e-06\n",
            "Epoch 56/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.8715 - dice_coef: 0.9123 - iou: 0.8389 - recall_1: 0.4396 - precision_1: 0.9962\n",
            "Epoch 56: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 528ms/step - loss: 0.0877 - accuracy: 0.8715 - dice_coef: 0.9123 - iou: 0.8389 - recall_1: 0.4396 - precision_1: 0.9962 - val_loss: 0.2549 - val_accuracy: 0.8777 - val_dice_coef: 0.7451 - val_iou: 0.5952 - val_recall_1: 0.3741 - val_precision_1: 0.9165 - lr: 1.0000e-06\n",
            "Epoch 57/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.8715 - dice_coef: 0.9124 - iou: 0.8391 - recall_1: 0.4396 - precision_1: 0.9962\n",
            "Epoch 57: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 529ms/step - loss: 0.0876 - accuracy: 0.8715 - dice_coef: 0.9124 - iou: 0.8391 - recall_1: 0.4396 - precision_1: 0.9962 - val_loss: 0.2549 - val_accuracy: 0.8777 - val_dice_coef: 0.7451 - val_iou: 0.5952 - val_recall_1: 0.3742 - val_precision_1: 0.9165 - lr: 1.0000e-06\n",
            "Epoch 58/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.8715 - dice_coef: 0.9125 - iou: 0.8392 - recall_1: 0.4396 - precision_1: 0.9962\n",
            "Epoch 58: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 531ms/step - loss: 0.0875 - accuracy: 0.8715 - dice_coef: 0.9125 - iou: 0.8392 - recall_1: 0.4396 - precision_1: 0.9962 - val_loss: 0.2549 - val_accuracy: 0.8777 - val_dice_coef: 0.7451 - val_iou: 0.5952 - val_recall_1: 0.3742 - val_precision_1: 0.9165 - lr: 1.0000e-06\n",
            "Epoch 59/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.8715 - dice_coef: 0.9125 - iou: 0.8393 - recall_1: 0.4396 - precision_1: 0.9962\n",
            "Epoch 59: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 32s 534ms/step - loss: 0.0875 - accuracy: 0.8715 - dice_coef: 0.9125 - iou: 0.8393 - recall_1: 0.4396 - precision_1: 0.9962 - val_loss: 0.2550 - val_accuracy: 0.8777 - val_dice_coef: 0.7450 - val_iou: 0.5952 - val_recall_1: 0.3741 - val_precision_1: 0.9165 - lr: 1.0000e-06\n",
            "Epoch 60/100\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.8715 - dice_coef: 0.9126 - iou: 0.8394 - recall_1: 0.4396 - precision_1: 0.9963\n",
            "Epoch 60: val_loss did not improve from 0.25480\n",
            "60/60 [==============================] - 31s 522ms/step - loss: 0.0874 - accuracy: 0.8715 - dice_coef: 0.9126 - iou: 0.8394 - recall_1: 0.4396 - precision_1: 0.9963 - val_loss: 0.2550 - val_accuracy: 0.8777 - val_dice_coef: 0.7450 - val_iou: 0.5952 - val_recall_1: 0.3741 - val_precision_1: 0.9165 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return ori_x, x\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
        "    line = np.ones((H, 10, 3)) * 255\n",
        "\n",
        "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
        "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255\n",
        "\n",
        "    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Save the results in this folder \"\"\"\n",
        "    create_dir(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/files/results1\")\n",
        "\n",
        "    \"\"\" Load the model \"\"\"\n",
        "    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
        "        model = tf.keras.models.load_model(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/files/model_chasedb.h5\")\n",
        "\n",
        "    \"\"\" Load the dataset \"\"\"\n",
        "    dataset_path = os.path.join(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/new_data\", \"test\")\n",
        "    test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "    \"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "    SCORE = []\n",
        "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "        \"\"\" Extracting name \"\"\"\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \"\"\" Read the image and mask \"\"\"\n",
        "        ori_x, x = read_image(x)\n",
        "        ori_y, y = read_mask(y)\n",
        "\n",
        "        \"\"\" Prediction \"\"\"\n",
        "        y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "        y_pred = y_pred > 0.5\n",
        "        y_pred = y_pred.astype(np.int32)\n",
        "        y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "        \"\"\" Saving the images \"\"\"\n",
        "        save_image_path = f\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/files/results1/{name}.png\"\n",
        "        save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "        \"\"\" Flatten the array \"\"\"\n",
        "        y = y.flatten()\n",
        "        y_pred = y_pred.flatten()\n",
        "\n",
        "        \"\"\" Calculate the metrics \"\"\"\n",
        "        acc_value = accuracy_score(y, y_pred)\n",
        "        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "    score = [s[1:] for s in SCORE]\n",
        "    score = np.mean(score, axis=0)\n",
        "    print(f\"Accuracy: {score[0]:0.5f}\")\n",
        "    print(f\"F1: {score[1]:0.5f}\")\n",
        "    print(f\"Jaccard: {score[2]:0.5f}\")\n",
        "    print(f\"Recall: {score[3]:0.5f}\")\n",
        "    print(f\"Precision: {score[4]:0.5f}\")\n",
        "\n",
        "    \"\"\" Saving \"\"\"\n",
        "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "    df.to_csv(\"/content/drive/My Drive/CCE-AIMIA/CHASEDB/files/score_chasedb.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmvT1E73UxGu",
        "outputId": "477c674b-e390-4bf7-99cb-2e67ddc6aa5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 331ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 1/8 [00:00<00:05,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 2/8 [00:01<00:03,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 3/8 [00:01<00:02,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 4/8 [00:02<00:01,  2.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 5/8 [00:02<00:01,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 6/8 [00:02<00:00,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 7/8 [00:03<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:03<00:00,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96056\n",
            "F1: 0.55520\n",
            "Jaccard: 0.38449\n",
            "Recall: 0.80055\n",
            "Precision: 0.42787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "tgR7MTiTFnZp",
        "outputId": "f4241ffe-5f18-46d1-d350-7404562e4feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}